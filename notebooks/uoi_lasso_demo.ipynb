{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import numpy as np\n",
    "\n",
    "from pyuoi.UoI_Lasso import UoI_Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates $UoI$ and `pyuoi` in action by applying $UoI_{Lasso}$ to synthetic data.\n",
    "\n",
    "$UoI$ is a framework for combining sparse model selection, via an intersection operation, with model estimation, via a union operation. For more details, see [the NIPS 2017 paper](https://papers.nips.cc/paper/6708-union-of-intersections-uoi-for-interpretable-data-driven-discovery-and-prediction). Different choices of intersection and union operations give rise to different concrete $UoI$ algorithms, denoted by $UoI_{XYZ}$.\n",
    "\n",
    "`pyuoi` implements several algorithms in the $UoI$ framework using the `sklearn` API.\n",
    "\n",
    "This notebook shows the `pyuoi.UoI_Lasso` implementation of the $UoI_{Lasso}$ algorithm, which chooses the Lasso algorithm as its intersection, or model selection, operation, and bagging as its union operation.\n",
    "\n",
    "This algorithm does not have an explicit prior over the parameters, but it assumes that the response vector $y$ can be well-described as a linear function $\\beta$ of the data $x$ plus Gaussian-distributed noise $\\epsilon$:\n",
    "\n",
    "$$\n",
    "y \\sim \\beta^\\top x + \\epsilon \\\\\n",
    "\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "It is most effective relative to other algorithms when $\\beta$ is _sparse_ in the $\\ell_0$ sense: when some fraction of the \"true\" values of $\\beta$ are exactly equal to $0$. The problem of choosing which variables should be non-zero is an example of a _model selection_ problem.\n",
    "\n",
    "A distribution with some values exactly equal to $0$ and some drawn from a different distribution is known as a _spike-and-slab distribution_. Because $UoI$ is designed to be relatively insensitive to the true distribution of the parameters, we explicitly allow, in this example, the generation of parameters with arbitrary distributions for the slab.\n",
    "\n",
    "The function `generate_model_and_data` below generates a true model and data according to the description above, with the distribution of non-zero parameters set by the `param_sampler` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_and_data(n_samples, n_features, num_nonzero, noise_scale, param_sampler=np.random.laplace):\n",
    "    # create design matrix\n",
    "    X = np.random.normal(size=(n_samples, n_features))\n",
    "    \n",
    "    # sample model parameters\n",
    "    beta = np.zeros(shape=(n_features, 1))\n",
    "    nonzero_idx = np.random.choice(np.arange(n_features), num_nonzero, replace=False)\n",
    "    beta[nonzero_idx, 0] = param_sampler(size=(num_nonzero))\n",
    "    \n",
    "    # sample noise\n",
    "    noise = np.random.normal(scale=noise_scale, size=(n_samples, 1))\n",
    "    \n",
    "    # generate response vector\n",
    "    y = np.dot(X, beta) + noise\n",
    "    \n",
    "    return X, y, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check model performance, we calculate and report the following metrics on the fit:\n",
    "- False Positive Rate: the fraction of parameters incorrectly selected.\n",
    "- False Negative Rate: the fraction of parameters incorrectly not selected.\n",
    "- (Relative) Bias: the ratio of the observed difference between true and estimated parameters to the $\\ell_1$ norm of the true parameters (the sum of absolute values).\n",
    "\n",
    "We further plot the true and recovered values of the parameters against each other.\n",
    "\n",
    "The functions in the cell below calculate and display these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FitMetrics = namedtuple(\"FitMetrics\",\n",
    "                        [\"false_positive_rate\", \"false_negative_rate\", \"bias\"])\n",
    "\n",
    "def calculate_fit_metrics(estimate, true):\n",
    "    false_positive_rate = np.count_nonzero(estimate[true == 0]) / len(true)\n",
    "    false_negative_rate = np.count_nonzero(true[estimate == 0]) / len(true)\n",
    "    relative_bias = (estimate - true) / np.sum(np.abs(true))\n",
    "    \n",
    "    return FitMetrics(false_positive_rate, false_negative_rate, relative_bias)\n",
    "\n",
    "def display_results_and_metrics(estimate, true, metrics):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.scatter(true, estimate)\n",
    "    ax.plot(ax.get_xlim(), ax.get_xlim(), linewidth=3)\n",
    "    ax.set_xlabel('True', fontsize=25)\n",
    "    ax.set_ylabel('Estimates', fontsize=25)\n",
    "    \n",
    "    print('False Positive Rate: ', metrics.false_positive_rate)\n",
    "    print('False Negative Rate: {}'.format(metrics.false_negative_rate))\n",
    "    print('Relative Bias: {:.4f}'.format(np.mean(metrics.bias)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are collected under `basic_test` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_test(n_features=10, n_samples=50, noise_scale=0.5, sparsity=0.,\n",
    "               param_sampler=np.random.laplace,\n",
    "               stratify=np.ones(10)):\n",
    "    \"\"\"Tests UoI Lasso on synthetic data and reports performance metrics on the fit.\n",
    "    \n",
    "    Data is sampled from a linear model with Gaussian error and parameters\n",
    "    from a spike-and-slab distribution. Spike height is determined by the\n",
    "    sparsity parameter; the slab is sampled from by param_sampler.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_features : int\n",
    "        Number of data features.\n",
    "        \n",
    "    n_samples : int\n",
    "        Number of data points to sample.\n",
    "        \n",
    "    noise_scale : float\n",
    "        Standard deviation of noise. Data has unit variance.\n",
    "        \n",
    "    sparsity: float\n",
    "        Ratio of parameters that are exactly 0.\n",
    "        \n",
    "    param_sampler: callable\n",
    "        Callable that returns a numpy array of values with shape (sz,)\n",
    "        when called with argument size=sz.\n",
    "        \n",
    "    stratify: array-like or None, default None\n",
    "        Ensures groups of samples are alloted to training/test sets\n",
    "        proportionally. Labels for each group must be an int greater\n",
    "        than zero. Must be of size equal to the number of samples, with\n",
    "        further restrictions on the number of groups.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    uoi : UoI_Lasso\n",
    "        The fit UoI Lasso model.\n",
    "        \n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "        The design matrix for the synthetic data.\n",
    "        \n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Response vector for the synthetic data.\n",
    "        \n",
    "    fit_metrics : FitMetrics\n",
    "        Namedtuple containing metrics on UoI Lasso's fit: false postive\n",
    "        and negative rate and average parameter value bias.\n",
    "    \"\"\"\n",
    "    # calculate number of nonzero parameters\n",
    "    num_nonzero = int((1 - sparsity) * n_features)\n",
    "    \n",
    "    # generate data according to a known (random) underlying model\n",
    "    X, y, beta = generate_model_and_data(n_samples, n_features, num_nonzero,\n",
    "                                         noise_scale, param_sampler)\n",
    "       \n",
    "    # run UoI Lasso\n",
    "    uoi = UoI_Lasso()\n",
    "    uoi.fit(X, y, stratify=stratify)\n",
    "    \n",
    "    # compute metrics\n",
    "    estimate, true = uoi.coef_, beta.ravel()\n",
    "    fit_metrics = calculate_fit_metrics(estimate, true)\n",
    "    \n",
    "    # display results\n",
    "    display_results_and_metrics(estimate, true, fit_metrics)\n",
    "    \n",
    "    return uoi, X, y, beta, fit_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uoi, X, y, beta, fit_metrics = basic_test(n_features=10, n_samples=400, sparsity=0.4,\n",
    "                                    stratify=np.concatenate((np.ones(200), 2*np.ones(200))),\n",
    "                                    param_sampler=np.random.laplace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
